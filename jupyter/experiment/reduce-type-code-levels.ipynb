{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reduce item_type_code_name levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%run '../lib/init.ipynb'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ..lib import utilities as util"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 589, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 447, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 254, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 74, in read_command\n    command = serializer._read_with_length(file)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 172, in _read_with_length\n    return self.loads(obj)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 458, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utilities'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPythonException\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-117-c3a7a069102f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mfilterDf\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mload_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'filterDf'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtypes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_var_types\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/jupyter/lib/utilities.py\u001B[0m in \u001B[0;36mget_var_types\u001B[0;34m(dfColumns)\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0mdescDf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'descDf'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 315\u001B[0;31m         \u001B[0mtype\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'identifierVars'\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mwhitelist\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mvariable_types_label\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdescDf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Categorical Identifier'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdfColumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    316\u001B[0m         \u001B[0mtype\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'nominalVars'\u001B[0m\u001B[0;34m]\u001B[0m     \u001B[0;34m=\u001B[0m \u001B[0mwhitelist\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mvariable_types_label\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdescDf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Categorical Nominal'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0mdfColumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m         \u001B[0mtype\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'continuousVars'\u001B[0m\u001B[0;34m]\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mwhitelist\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mvariable_types_label\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdescDf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Numeric Continuous'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvariable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m   \u001B[0mdfColumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/jupyter/lib/utilities.py\u001B[0m in \u001B[0;36mvariable_types_label\u001B[0;34m(df, type)\u001B[0m\n\u001B[1;32m    765\u001B[0m             \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat_ws\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m' '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'field'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0minitials_udf\u001B[0m\u001B[0;34m(\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'category'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m)\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malias\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'variable_label'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    766\u001B[0m             \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'field'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malias\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'variable'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 767\u001B[0;31m         ).orderBy('category', 'variable').toPandas()\n\u001B[0m\u001B[1;32m    768\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    769\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36mtoPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m         \u001B[0;31m# Below is toPandas without Arrow optimization.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 138\u001B[0;31m         \u001B[0mpdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    139\u001B[0m         \u001B[0mcolumn_counter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCounter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36mcollect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    594\u001B[0m         \"\"\"\n\u001B[1;32m    595\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mSCCallSiteSync\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcss\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m             \u001B[0msock_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollectToPython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    597\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_load_from_socket\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msock_info\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBatchedSerializer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPickleSerializer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1304\u001B[0m         return_value = get_return_value(\n\u001B[0;32m-> 1305\u001B[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0m\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1307\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtemp_arg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    132\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    133\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 134\u001B[0;31m                 \u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    135\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(e)\u001B[0m\n",
      "\u001B[0;31mPythonException\u001B[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 589, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 447, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 254, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 74, in read_command\n    command = serializer._read_with_length(file)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 172, in _read_with_length\n    return self.loads(obj)\n  File \"/Users/duane.hinkley/PycharmProjects/c772-capstone-project/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 458, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utilities'\n"
     ]
    }
   ],
   "source": [
    "filterDf  = util.load_df('filterDf')\n",
    "types = util.get_var_types()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Display levels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|item_type_code_name   |count|\n",
      "+----------------------+-----+\n",
      "|multipleChoice        |26704|\n",
      "|fillInTheBlank        |10497|\n",
      "|equationEntry         |7841 |\n",
      "|trueFalse             |4561 |\n",
      "|cloze                 |3024 |\n",
      "|multipleSelect        |2295 |\n",
      "|graphing              |2076 |\n",
      "|MultipleChoiceResponse|1550 |\n",
      "|choiceMatrix          |1203 |\n",
      "|matching              |924  |\n",
      "|shortAnswer           |853  |\n",
      "|selectText            |813  |\n",
      "|bucketing             |799  |\n",
      "|sortable              |549  |\n",
      "|essay                 |531  |\n",
      "|numberLine            |302  |\n",
      "|aheAlgo               |219  |\n",
      "|imageLabel            |80   |\n",
      "|RubricResponse        |11   |\n",
      "|FillinBlankResponse   |5    |\n",
      "|fileUpload            |1    |\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "util.count_values(filterDf, 'item_type_code_name').show(50, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Display item_type_code_name and scoring_type_code Corelation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "scoring_type_code       [unassigned]  automatic  external  manual  Total\nitem_type_code_name                                                     \nFillinBlankResponse                5          0         0       0      5\nMultipleChoiceResponse          1550          0         0       0   1550\nRubricResponse                    11          0         0       0     11\naheAlgo                            0          0       219       0    219\nbucketing                          0        799         0       0    799\nchoiceMatrix                       0       1203         0       0   1203\ncloze                              0       3024         0       0   3024\nequationEntry                      0       7841         0       0   7841\nessay                              9          0         0     522    531\nfileUpload                         0          0         0       1      1\nfillInTheBlank                     0      10497         0       0  10497\ngraphing                           0       2076         0       0   2076\nimageLabel                         0         80         0       0     80\nmatching                           0        924         0       0    924\nmultipleChoice                     0      26704         0       0  26704\nmultipleSelect                     0       2295         0       0   2295\nnumberLine                         0        302         0       0    302\nselectText                         0        813         0       0    813\nshortAnswer                       25          0         0     828    853\nsortable                           0        549         0       0    549\ntrueFalse                          0       4561         0       0   4561\nTotal                           1600      61668       219    1351  64838",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>scoring_type_code</th>\n      <th>[unassigned]</th>\n      <th>automatic</th>\n      <th>external</th>\n      <th>manual</th>\n      <th>Total</th>\n    </tr>\n    <tr>\n      <th>item_type_code_name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FillinBlankResponse</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>MultipleChoiceResponse</th>\n      <td>1550</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1550</td>\n    </tr>\n    <tr>\n      <th>RubricResponse</th>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>aheAlgo</th>\n      <td>0</td>\n      <td>0</td>\n      <td>219</td>\n      <td>0</td>\n      <td>219</td>\n    </tr>\n    <tr>\n      <th>bucketing</th>\n      <td>0</td>\n      <td>799</td>\n      <td>0</td>\n      <td>0</td>\n      <td>799</td>\n    </tr>\n    <tr>\n      <th>choiceMatrix</th>\n      <td>0</td>\n      <td>1203</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1203</td>\n    </tr>\n    <tr>\n      <th>cloze</th>\n      <td>0</td>\n      <td>3024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3024</td>\n    </tr>\n    <tr>\n      <th>equationEntry</th>\n      <td>0</td>\n      <td>7841</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7841</td>\n    </tr>\n    <tr>\n      <th>essay</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>522</td>\n      <td>531</td>\n    </tr>\n    <tr>\n      <th>fileUpload</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>fillInTheBlank</th>\n      <td>0</td>\n      <td>10497</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10497</td>\n    </tr>\n    <tr>\n      <th>graphing</th>\n      <td>0</td>\n      <td>2076</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2076</td>\n    </tr>\n    <tr>\n      <th>imageLabel</th>\n      <td>0</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>matching</th>\n      <td>0</td>\n      <td>924</td>\n      <td>0</td>\n      <td>0</td>\n      <td>924</td>\n    </tr>\n    <tr>\n      <th>multipleChoice</th>\n      <td>0</td>\n      <td>26704</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26704</td>\n    </tr>\n    <tr>\n      <th>multipleSelect</th>\n      <td>0</td>\n      <td>2295</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2295</td>\n    </tr>\n    <tr>\n      <th>numberLine</th>\n      <td>0</td>\n      <td>302</td>\n      <td>0</td>\n      <td>0</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>selectText</th>\n      <td>0</td>\n      <td>813</td>\n      <td>0</td>\n      <td>0</td>\n      <td>813</td>\n    </tr>\n    <tr>\n      <th>shortAnswer</th>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>828</td>\n      <td>853</td>\n    </tr>\n    <tr>\n      <th>sortable</th>\n      <td>0</td>\n      <td>549</td>\n      <td>0</td>\n      <td>0</td>\n      <td>549</td>\n    </tr>\n    <tr>\n      <th>trueFalse</th>\n      <td>0</td>\n      <td>4561</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4561</td>\n    </tr>\n    <tr>\n      <th>Total</th>\n      <td>1600</td>\n      <td>61668</td>\n      <td>219</td>\n      <td>1351</td>\n      <td>64838</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPd = filterDf.select('item_type_code_name','scoring_type_code').toPandas()\n",
    "pd.crosstab(dfPd.item_type_code_name.fillna('null'), dfPd.scoring_type_code.fillna('null'), margins=True, margins_name=\"Total\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- unassigned\n",
    "    - FillinBlankResponse\n",
    "    - MultipleChoiceResponse\n",
    "    - shortAnswer\n",
    "- manual\n",
    "  - aheAlg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|item_type_code_name|item_type_code_name_swoe|\n",
      "+-------------------+------------------------+\n",
      "|         fileUpload|       0.958169577610213|\n",
      "|FillinBlankResponse|      0.6523843277995943|\n",
      "|FillinBlankResponse|      0.6523843277995943|\n",
      "|FillinBlankResponse|      0.6523843277995943|\n",
      "|FillinBlankResponse|      0.6523843277995943|\n",
      "|FillinBlankResponse|      0.6523843277995943|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "|      equationEntry|      0.6998692812113955|\n",
      "+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "util.encode_categories_as_swoe(filterDf).select('item_type_code_name', 'item_type_code_name_swoe').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------------------+------------------+\n",
      "|  0|   1|                woe|                iv|\n",
      "+---+----+-------------------+------------------+\n",
      "|0.6|0.25|-0.8754687373538999|0.5924584552018219|\n",
      "|0.2| 0.5| 0.9162907318741551|0.5924584552018219|\n",
      "|0.2|0.25|0.22314355131420976|0.5924584552018219|\n",
      "+---+----+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def swoe2(df):\n",
    "    # Ref: https://www.researchgate.net/profile/Goutam_Chakraborty4/publication/259184404_Extension_Node_to_the_Rescue_of_the_Curse_of_Dimensionality_via_Weight_of_Evidence_WOE_Recoding/links/0c96052a3a083b6ccd000000.pdf\n",
    "\n",
    "    # Smoothing parameter.  large = aggressive, small = sensitive to data\n",
    "    c = 24\n",
    "    # Get portion of events\n",
    "    p1 = df.select('target').toPandas().target.mean()\n",
    "\n",
    "    # Get event and non event counts\n",
    "    cntDf =  df.groupBy('cat').agg(\n",
    "        F.sum( F.when( F.col('target')  > 0, 1 ).otherwise(0)).alias('1'),\n",
    "        F.sum( F.when( F.col('target') == 0, 1 ).otherwise(0)).alias('0')\n",
    "    )\n",
    "    # Add swoe\n",
    "    # Formula:\n",
    "    #           # events + cp1\n",
    "    # ln( ----------------------- )\n",
    "    #     # nonevents + c(1 - p1)\n",
    "    cntDf = cntDf.withColumn(\n",
    "        'cat_swoe',\n",
    "        F.log( (F.col('1') +  c * p1)  / (F.col('0') + c * (1 - p1)))\n",
    "    )\n",
    "    return df.join(cntDf.select('cat', 'cat_swoe'), 'cat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'cat': ['a', 'b', 'a', 'b', 'a', 'a', 'b', 'c', 'c'],\n",
    "     'target': [1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "     })\n",
    "\n",
    "feature,target = 'cat','target'\n",
    "df_woe_iv = (pd.crosstab(df[feature],df[target],\n",
    "                      normalize='columns')\n",
    "             .assign(woe=lambda dfx: np.log(dfx[1] / dfx[0]))\n",
    "             .assign(iv=lambda dfx: np.sum(dfx['woe']*\n",
    "                                           (dfx[1]-dfx[0]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "target    0     1       woe        iv\ncat                                  \na       0.6  0.25 -0.875469  0.592458\nb       0.2  0.50  0.916291  0.592458\nc       0.2  0.25  0.223144  0.592458",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>0</th>\n      <th>1</th>\n      <th>woe</th>\n      <th>iv</th>\n    </tr>\n    <tr>\n      <th>cat</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>0.6</td>\n      <td>0.25</td>\n      <td>-0.875469</td>\n      <td>0.592458</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>0.2</td>\n      <td>0.50</td>\n      <td>0.916291</td>\n      <td>0.592458</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>0.2</td>\n      <td>0.25</td>\n      <td>0.223144</td>\n      <td>0.592458</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_woe_iv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Ref: https://github.com/albertusk95/weight-of-evidence-spark\n",
    "\n",
    "class WOE_IV(object):\n",
    "    def __init__(self, df: DataFrame, cols_to_woe: [str], label_column: str, good_label: str):\n",
    "        self.df = df\n",
    "        self.cols_to_woe = cols_to_woe\n",
    "        self.label_column = label_column\n",
    "        self.good_label = good_label\n",
    "        self.fit_data = {}\n",
    "\n",
    "    def fit(self):\n",
    "        for col_to_woe in self.cols_to_woe:\n",
    "            total_good = self.compute_total_amount_of_good()\n",
    "            total_bad = self.compute_total_amount_of_bad()\n",
    "\n",
    "            woe_df = self.df.select(col_to_woe)\n",
    "            categories = woe_df.distinct().collect()\n",
    "            for category_row in categories:\n",
    "                category = category_row[col_to_woe]\n",
    "                good_amount = self.compute_good_amount(col_to_woe, category)\n",
    "                bad_amount = self.compute_bad_amount(col_to_woe, category)\n",
    "\n",
    "                good_amount = good_amount if good_amount != 0 else 0.5\n",
    "                bad_amount = bad_amount if bad_amount != 0 else 0.5\n",
    "\n",
    "                good_dist = good_amount / total_good\n",
    "                bad_dist = bad_amount / total_bad\n",
    "\n",
    "                self.build_fit_data(col_to_woe, category, good_dist, bad_dist)\n",
    "\n",
    "    def transform(self, df: DataFrame):\n",
    "        def _encode_woe(col_to_woe_):\n",
    "            return F.coalesce(\n",
    "                *[F.when(F.col(col_to_woe_) == category, F.lit(woe_iv['woe']))\n",
    "                  for category, woe_iv in self.fit_data[col_to_woe_].items()]\n",
    "            )\n",
    "\n",
    "        for col_to_woe, woe_info in self.fit_data.items():\n",
    "            df = df.withColumn(col_to_woe + '_woe', _encode_woe(col_to_woe))\n",
    "        return df\n",
    "\n",
    "    def compute_total_amount_of_good(self):\n",
    "        return self.df.select(self.label_column).filter(F.col(self.label_column) == self.good_label).count()\n",
    "\n",
    "    def compute_total_amount_of_bad(self):\n",
    "        return self.df.select(self.label_column).filter(F.col(self.label_column) != self.good_label).count()\n",
    "\n",
    "    def compute_good_amount(self, col_to_woe: str, category: str):\n",
    "        return self.df.select(col_to_woe, self.label_column)\\\n",
    "                      .filter(\n",
    "                            (F.col(col_to_woe) == category) & (F.col(self.label_column) == self.good_label)\n",
    "                      ).count()\n",
    "\n",
    "    def compute_bad_amount(self, col_to_woe: str, category: str):\n",
    "        return self.df.select(col_to_woe, self.label_column)\\\n",
    "                      .filter(\n",
    "                            (F.col(col_to_woe) == category) & (F.col(self.label_column) != self.good_label)\n",
    "                      ).count()\n",
    "\n",
    "    def build_fit_data(self, col_to_woe, category, good_dist, bad_dist):\n",
    "        woe_info = {\n",
    "            category: {\n",
    "                'woe': math.log(good_dist / bad_dist),\n",
    "                'iv': (good_dist - bad_dist) * math.log(good_dist / bad_dist)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if col_to_woe not in self.fit_data:\n",
    "            self.fit_data[col_to_woe] = woe_info\n",
    "        else:\n",
    "            self.fit_data[col_to_woe].update(woe_info)\n",
    "\n",
    "    def compute_iv(self):\n",
    "        iv_dict = {}\n",
    "\n",
    "        for woe_col, categories in self.fit_data.items():\n",
    "            iv_dict[woe_col] = 0\n",
    "            for category, woe_iv in categories.items():\n",
    "                iv_dict[woe_col] += woe_iv['iv']\n",
    "        return iv_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|cat|target|\n",
      "+---+------+\n",
      "|  a|     1|\n",
      "|  b|     0|\n",
      "|  a|     0|\n",
      "|  b|     1|\n",
      "|  a|     0|\n",
      "|  a|     0|\n",
      "|  b|     1|\n",
      "|  c|     1|\n",
      "|  c|     0|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'cat': ['a', 'b', 'a', 'b', 'a', 'a', 'b', 'c', 'c'],\n",
    "     'target': [1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "     })\n",
    "spDf = spark.createDataFrame(df)\n",
    "\n",
    "spDf.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "cols_to_woe = ['cat']\n",
    "label_col = 'target'\n",
    "good_label = 1\n",
    "\n",
    "woe = WOE_IV(spDf, cols_to_woe, label_col, good_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "woe.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "target    0     1       woe        iv\ncat                                  \na       0.6  0.25 -0.875469  0.592458\nb       0.2  0.50  0.916291  0.592458\nc       0.2  0.25  0.223144  0.592458",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>target</th>\n      <th>0</th>\n      <th>1</th>\n      <th>woe</th>\n      <th>iv</th>\n    </tr>\n    <tr>\n      <th>cat</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>0.6</td>\n      <td>0.25</td>\n      <td>-0.875469</td>\n      <td>0.592458</td>\n    </tr>\n    <tr>\n      <th>b</th>\n      <td>0.2</td>\n      <td>0.50</td>\n      <td>0.916291</td>\n      <td>0.592458</td>\n    </tr>\n    <tr>\n      <th>c</th>\n      <td>0.2</td>\n      <td>0.25</td>\n      <td>0.223144</td>\n      <td>0.592458</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_woe_iv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------------+\n",
      "|cat|target|            cat_woe|\n",
      "+---+------+-------------------+\n",
      "|  a|     1|-0.8754687373538999|\n",
      "|  b|     0| 0.9162907318741551|\n",
      "|  a|     0|-0.8754687373538999|\n",
      "|  b|     1| 0.9162907318741551|\n",
      "|  a|     0|-0.8754687373538999|\n",
      "|  a|     0|-0.8754687373538999|\n",
      "|  b|     1| 0.9162907318741551|\n",
      "|  c|     1|0.22314355131420976|\n",
      "|  c|     0|0.22314355131420976|\n",
      "+---+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "woe.transform(spDf).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cat': 0.5924584552018219}"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woe.compute_iv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}