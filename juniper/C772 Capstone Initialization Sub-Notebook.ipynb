{"cells":[{"cell_type":"markdown","source":["#### Data Exploration: Initialize Functions"],"metadata":{}},{"cell_type":"code","source":["%sh\n# The Search for Categorical Correlation\n# https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n# https://github.com/shakedzy/dython\n# http://shakedzy.xyz/dython/\npip install dython"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting dython\n  Downloading dython-0.6.1-py3-none-any.whl (16 kB)\nRequirement already satisfied: seaborn in /databricks/python3/lib/python3.7/site-packages (from dython) (0.10.0)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.7/site-packages (from dython) (3.1.3)\nRequirement already satisfied: pandas&gt;=0.23.4 in /databricks/python3/lib/python3.7/site-packages (from dython) (1.0.1)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.7/site-packages (from dython) (0.22.1)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.7/site-packages (from dython) (1.4.1)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from dython) (1.18.1)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.7/site-packages (from matplotlib-&gt;dython) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /databricks/python3/lib/python3.7/site-packages (from matplotlib-&gt;dython) (2.4.6)\nRequirement already satisfied: python-dateutil&gt;=2.1 in /databricks/python3/lib/python3.7/site-packages (from matplotlib-&gt;dython) (2.8.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.7/site-packages (from matplotlib-&gt;dython) (1.1.0)\nRequirement already satisfied: pytz&gt;=2017.2 in /databricks/python3/lib/python3.7/site-packages (from pandas&gt;=0.23.4-&gt;dython) (2019.3)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.7/site-packages (from scikit-learn-&gt;dython) (0.14.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from cycler&gt;=0.10-&gt;matplotlib-&gt;dython) (1.14.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;dython) (45.2.0)\nInstalling collected packages: dython\nSuccessfully installed dython-0.6.1\nWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\nYou should consider upgrading via the &#39;/databricks/python3/bin/python3.7 -m pip install --upgrade pip&#39; command.\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport random\n\nfrom pyspark import SparkContext\nfrom pyspark import SparkFiles\nfrom pyspark.sql.types import StructType, StructField, StringType, BooleanType\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import types as T\n\nfrom itertools import chain\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\n# https://github.com/shakedzy/dython\nfrom dython.nominal import associations\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Create Todo list\ndef init_todo():\n  global todoList\n  schema = StructType([\n    StructField('todo', StringType(), True),\n    StructField('finished', BooleanType(), True)\n  ])\n  todoList = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n\ndef add_todo(desc):\n  global todoList\n  newRow = spark.createDataFrame([(desc,False)])\n  todoList = todoList.union(newRow)\n  \ndef list_todo():\n  global todoList\n  display(todoList)\n  \ndef finish_todo(desc):\n  global todoList\n  todoList = todoList.withColumn(\n    \"finished\",\n    F.when(\n        F.col(\"todo\") == desc,\n        True\n     ).otherwise(F.col(\"finished\"))\n   )\n\ninit_todo()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["import os\nfrom pyspark import SparkFiles\n\ndef import_by_url(url):\n  # Given a url to a csv file, import and return a dataframe\n  #\n  spark.sparkContext.addFile(url)\n  filename = os.path.basename(url)\n  file = \"file://\" + SparkFiles.get(filename)\n  return spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(file)\n\n\ndef filter_default(dfIn, f1, f2):\n  # Given a dataframe and two date field names, returns the dataframe removing records \n  # where the f1 or f2 columns equal a default date\n  defaultDates = [\"2999-01-01 00:00:00\", \"1900-01-01 00:00:00\"]\n  return dfIn.filter( ~F.col(f1).isin(defaultDates) & ~F.col(f2).isin(defaultDates) )\n\n\ndef date_stats(dfIn, f1, f2):\n  # Given a dataframe and two date field names, returns a new dataframe with the difference between\n  # the dates in minutes, hours and minutes\n  dfOut = filter_default(dfIn, f1, f2)\n\n  dfOut = dfOut.withColumn(\"minues\", (F.col(f1).cast(\"long\") - F.col(f2).cast(\"long\"))/60.).select(f1, f2, \"minues\")\n\n  dfOut = dfOut.withColumn(\"hours\", (F.col(f1).cast(\"long\") - F.col(f2).cast(\"long\"))/3600.).select(f1, f2, \"hours\", \"minues\")\n\n  return dfOut.withColumn(\"days\", (F.col(f1).cast(\"long\") - F.col(f2).cast(\"long\"))/86400.).select(\"days\", \"hours\", \"minues\")\n\n\ndef annotate_plot(ax):\n  # Add total labels to plot\n  for p in ax.patches:\n      ax.annotate( \n        round(p.get_height(), 2),\n        (p.get_x()+p.get_width()/2., p.get_height()),\n        ha='center',\n        va='center',\n        color='white',\n        fontweight='bold',\n        xytext=(0, -10),\n        textcoords='offset points')\n      \n      \n\ndef perfect_cor(df, groupCol):\n    \"\"\" Give a dataframe, and a column to group by return a list of \n        perfectly correlated variables\n    \"\"\"\n\n    exCols = []\n\n    # Count distinct values of rows where assignment_start_date is null\n    dfCounts = df.groupBy(groupCol).agg(*(F.countDistinct( F.when(F.col(c).isNull(), \"Empty\").otherwise(F.col(c).cast(\"string\") ) ).alias(c) for c in df.columns))\n\n    # Filter fields to those with count of 1\n    for row in dfCounts.collect():\n      for c in dfCounts.columns:\n        if (row[c] != 1):\n          exCols.append(c)\n\n\n    exCols  = list(set(exCols)) # Get unique list\n    allCols = dfCounts.columns\n    inCols  = [col for col in allCols if col not in exCols] # Return cols not in exCols\n\n    return inCols;\n\ndef id_to_name(df, idVar, newVar, newIdList):\n  # Given a dataframe, id variable, new variable name and list of new ids\n  # add a new variable to the dataframe mapping the id to the array\n  \n  # Save org ids to a list\n  oldIdList = [row[idVar] for row in df.select(idVar).distinct().orderBy(idVar).collect()]\n\n    # Create map\n  newIdMap = dict()\n  # Add letters to map \n  for i, val in enumerate(oldIdList): \n      newIdMap[val] = newIdList[i]\n\n  # Create mapping expression\n  mapping_expr = F.create_map([F.lit(x) for x in chain(*newIdMap.items())])\n\n  # Add org column with letter related to id\n  return df.withColumn(newVar, mapping_expr[df[idVar]])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["#### Data Exploration: Initialize Data"],"metadata":{}},{"cell_type":"code","source":["dfRaw = import_by_url('https://github.com/dlhinkley/c772-capstone-project/raw/master/data/assessment_items.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["dfDesc = import_by_url('https://github.com/dlhinkley/c772-capstone-project/raw/master/data/descriptions.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"C772 Capstone Initialization Sub-Notebook","notebookId":199670002752820},"nbformat":4,"nbformat_minor":0}
